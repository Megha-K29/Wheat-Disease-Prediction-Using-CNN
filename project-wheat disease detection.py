# -*- coding: utf-8 -*-
"""Wheat Disease Prediction.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1JAJu8fUG2EGdAJ_260mnbXI2XfceFZU_
"""



from google.colab import drive
drive.mount('/content/drive')

!cp "/content/drive/MyDrive/Wheat_data.zip" "/content"

!mkdir wheat1

!unzip /content/drive/MyDrive/Wheat_data.zip -d "/content/wheat1"

import numpy as np
import tensorflow as tf
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D,MaxPooling2D,Flatten,Dense
from tensorflow.keras.preprocessing.image import ImageDataGenerator

data_dir="/content/wheat1/Wheat_data/train"
data_dir1="/content/wheat1/Wheat_data/val"
data= tf.keras.preprocessing.image_dataset_from_directory(data_dir)
data= tf.keras.preprocessing.image_dataset_from_directory(data_dir1)

batch_size=32
epochs=15
image_size=(150,150)

train_datagen=ImageDataGenerator(
    rescale=1./255,
    validation_split=0.2
)

train_data=train_datagen.flow_from_directory(
    data_dir,
    target_size=image_size,
    batch_size=batch_size,
    class_mode="categorical",
    subset="training"

)

valid_datagen=ImageDataGenerator(
    rescale= 1./255,
    validation_split=0.2
)

validation_generator=valid_datagen.flow_from_directory(
    data_dir1,
    target_size=image_size,
    batch_size=batch_size,
    class_mode="categorical",
    subset="validation"
)

from tensorflow.keras.layers import Dropout

model = Sequential()
model.add(Conv2D(32,(3,3),activation="relu",input_shape=(150,150,3)))
model.add(MaxPooling2D(2,2))
model.add(Dropout(0.25))

model.add(Conv2D(64,(3,3),activation="relu",input_shape=(150,150,3)))
model.add(MaxPooling2D(2,2))
model.add(Dropout(0.25))

model.add(Conv2D(64,(3,3),activation="relu",input_shape=(150,150,3)))
model.add(MaxPooling2D(2,2))
model.add(Dropout(0.25))

model.add(Flatten())

model.add(Dense(128,activation="relu"))
model.add(Dropout(0.5))
model.add(Dense(3,activation="softmax"))
model.summary()

model.compile(loss="categorical_crossentropy",optimizer="adam",metrics=["accuracy"])

history=model.fit(
    train_data,
    steps_per_epoch= train_data.samples//batch_size,
    validation_data=validation_generator,
    validation_steps=validation_generator.samples//batch_size,
    epochs=epochs
)

import matplotlib.pyplot as plt

plt.plot(history.history["accuracy"],label="accuracy")
plt.plot(history.history["val_accuracy"],label="val_accuracy")
plt.title("accuracy")
plt.xlabel("epoch")
plt.ylabel("accuracy")
plt.ylim([0.5,1])
plt.legend(loc="lower right")
plt.show()

model.save("Wheat")

class_map = train_data.class_indices
classes = []
for key in class_map.keys():
    classes.append(key)

from keras.preprocessing.image import load_img, img_to_array

def predict_image(filename, model):
    img_ = image.load_img(filename, target_size=(150, 150))
    img_array = image.img_to_array(img_)
    img_processed = np.expand_dims(img_array, axis=0)
    img_processed /= 255.

    prediction = model.predict(img_processed)

    index = np.argmax(prediction)

    plt.title("Prediction - {}".format(str(classes[index]).title()), size=18, color='red')
    plt.imshow(img_array)

from tensorflow.keras.preprocessing import image

def predict_image(image):
  img=image.load_img(image,target_size = image_size)
  img=image,img_to_array(img)
  img=np.expand_dims(img,axis=0)

predict_image('/content/Yellow_rust1133.jpg', model)

